itemEdgeGraph = graph.data.frame(itemEdgeList)
itemDist = shortest.paths(itemEdgeGraph, v = "0", mode = "out")
fbsItemCodes = colnames(itemDist)[is.finite(itemDist)]
fbsItemCodes
}
lossItems = getLossItemCPC()
## NOTE (Michael): The cpc tree loaded in the loss data set is
##                 different to the rest. Thus I can not query
##                 item such as 0419.
lossKey = DatasetKey(
domain = "lossWaste",
dataset = "loss",
dimensions = list(
Dimension(name = areaVar,
keys = allCountries),
Dimension(name = elementVar,
keys = "5120"),
Dimension(name = itemVar,
keys = lossItems),
Dimension(name = yearVar,
keys = selectedYear)
)
)
## Pivot to vectorize yield computation
lossPivot = c(
Pivoting(code = areaVar, ascending = TRUE),
Pivoting(code = itemVar, ascending = TRUE),
Pivoting(code = yearVar, ascending = FALSE),
Pivoting(code = elementVar, ascending = TRUE)
)
## Query the data
lossQuery = GetData(
key = lossKey,
flags = TRUE,
normalized = FALSE,
pivoting = lossPivot
)
setnames(lossQuery,
old = grep(elementVar,
colnames(lossQuery), value = TRUE),
new = gsub(elementVar, "measuredElement",
grep(elementVar,
colnames(lossQuery), value = TRUE)))
setnames(lossQuery,
old = itemVar,
new = itemAgVar)
## Convert time to numeric
lossQuery[, timePointYears := as.numeric(timePointYears)]
lossQuery[flagObservationStatus_measuredElement_5120 == "", ]
}
getSelectedLossData = function(){
## Pivot to vectorize yield computation
lossPivot = c(
Pivoting(code = areaVar, ascending = TRUE),
Pivoting(code = itemVar, ascending = TRUE),
Pivoting(code = yearVar, ascending = FALSE),
Pivoting(code = elementVar, ascending = TRUE)
)
## Query the data
lossQuery = GetData(
key = swsContext.datasets[[1]],
normalized = FALSE,
pivoting = lossPivot
)
setnames(lossQuery,
old = grep(elementVar,
colnames(lossQuery), value = TRUE),
new = gsub(elementVar, "measuredElement",
grep(elementVar,
colnames(lossQuery), value = TRUE)))
setnames(lossQuery,
old = itemVar,
new = itemAgVar)
## Convert time to numeric
lossQuery[, timePointYears := as.numeric(timePointYears)]
lossQuery
}
##' The above getSelectedLossData function only pulls in loss observations that
##' are available.  Clearly that's not right: we want to estimate loss for all
##' missing values, not just ones where we currently have estimates.
getSelectedLossData = function(){
dimensions = lapply(swsContext.datasets[[1]]@dimensions, function(x){
out = data.table(mergeKey = 1, value = x@keys)
setnames(out, "value", x@name)
})
lossQuery = merge(dimensions[[1]], dimensions[[4]], by = "mergeKey")
lossQuery = merge(lossQuery, dimensions[[2]], by = "mergeKey")
lossQuery[, mergeKey := NULL]
lossQuery[, Value_measuredElement_5120 := 0]
lossQuery[, flagObservationStatus_measuredElement_5120 := "M"]
lossQuery[, flagMethod_measuredElement_5120 := "u"]
setnames(lossQuery,
old = grep(elementVar,
colnames(lossQuery), value = TRUE),
new = gsub(elementVar, "measuredElement",
grep(elementVar,
colnames(lossQuery), value = TRUE)))
setnames(lossQuery,
old = itemVar,
new = itemAgVar)
## Convert time to numeric
lossQuery[, timePointYears := as.numeric(timePointYears)]
lossQuery
}
getLossWorldBankData = function(){
allCountries =
GetCodeList(domain = "WorldBank",
dataset = "wb_ecogrw",
dimension = areaVar)[type == "country", code]
infrastructureKey =
DatasetKey(domain = "WorldBank",
dataset = "wb_infrastructure",
dimensions =
list(
Dimension(name = areaVar,
keys = allCountries),
Dimension(name = "wbIndicator",
keys = "IS.ROD.PAVE.ZS"),
Dimension(name = yearVar,
keys = selectedYear)
)
)
gdpKey =
DatasetKey(domain = "WorldBank",
dataset = "wb_ecogrw",
dimensions =
list(
Dimension(name = areaVar,
keys = allCountries),
Dimension(name = "wbIndicator",
keys = c("NY.GDP.MKTP.PP.KD",
"NY.GDP.PCAP.KD")),
Dimension(name = yearVar,
keys = selectedYear)
)
)
newPivot = c(
Pivoting(code = areaVar, ascending = TRUE),
Pivoting(code = "wbIndicator", ascending = TRUE),
Pivoting(code = yearVar, ascending = FALSE)
)
base =
data.table(geographicAreaM49 = character(),
wbIndicator = character(),
timePointYears = character(),
Value = numeric())
merged =
Reduce(f = function(base, key){
rbind(base, GetData(key, pivoting = newPivot))
}, x = list(infrastructureKey, gdpKey), init = base)
casted =
dcast.data.table(merged,
geographicAreaM49 + timePointYears ~ wbIndicator,
value.var = "Value")
setnames(casted,
old = c("IS.ROD.PAVE.ZS", "NY.GDP.MKTP.PP.KD",
"NY.GDP.PCAP.KD"),
new = c("sharePavedRoad", "gdpPPP", "gdpPerCapita"))
casted[, timePointYears := as.numeric(timePointYears)]
setkeyv(casted, cols = c(areaVar, yearVar))
casted
}
## Function to load the loss food group classification
getLossFoodGroup = function(){
lossFoodGroup = GetTableData(schemaName = "ess", tableName = "loss_food_group")
setnames(lossFoodGroup, old = colnames(lossFoodGroup),
new = c("measuredItemFS", "measuredItemNameFS", "foodGroupName",
"foodGroup", "foodGeneralGroup", "foodPerishableGroup",
"measuredItemCPC"))
lossFoodGroup[, list(measuredItemCPC, foodGroupName,
foodGeneralGroup, foodPerishableGroup)]
lossFoodGroup
}
## Function to load the loss region classification
getLossRegionClass = function(){
regionMapping =
GetTableData(schemaName = "ess", tableName = "loss_region_mapping")
setnames(regionMapping, old = colnames(regionMapping),
new = c("geographicAreaM49", "lossRegionClass"))
regionMapping
}
imputeSharePavedRoad = function(wbData, pavedRoadVar){
foo = function(x){
if(length(na.omit(x)) >= 2){
tmp = na.locf(na.approx(x, na.rm = FALSE), na.rm = FALSE)
} else {
tmp = x
}
tmp
}
wbData[, `:=`(c(pavedRoadVar),
foo(.SD[[pavedRoadVar]])),
by = "geographicAreaM49"]
}
mergeAllLossData = function(lossData, ...){
explanatoryData = list(...)
Reduce(f = function(x, y){
keys = intersect(colnames(x), colnames(y))
setkeyv(x, keys)
setkeyv(y, keys)
merge(x, y, all.x = TRUE)
},
x = explanatoryData, init = lossData
)
}
removeCarryLoss = function(data, lossVar){
data[, variance := var(.SD[[lossVar]], na.rm = TRUE),
by = c("geographicAreaM49", "measuredItemCPC")]
data[, duplicateValue := duplicated(.SD[[lossVar]]),
by = c("geographicAreaM49", "measuredItemCPC")]
data = data[!(variance == 0 & duplicateValue), ]
data[, `:=`(c("variance", "duplicateValue"), NULL)]
data
}
imputeLoss = function(data, lossVar, lossObservationFlagVar, lossMethodFlagVar,
lossModel, lossVarModel){
imputedData = copy(data)
imputedData[, lossPredicted := exp(predict(lossModel, newdata = imputedData,
allow.new.levels = TRUE))]
imputedData[(is.na(imputedData[[lossVar]]) |
imputedData[[lossObservationFlagVar]] %in% c("E", "I", "T", "M")) &
!is.na(lossPredicted),
`:=`(c(lossVar, lossObservationFlagVar, lossMethodFlagVar),
list(lossPredicted, "I", "e"))]
imputedData[, lossPredicted := NULL]
imputedData[, lossVariance := apply(lossLmeVariance$t, 2, sd)]
imputedData
}
swsContext.datasets = list()
swsContext.datasets[[1]] = DatasetKey(
domain = "agriculture",
dataset = "agriculture",
dimensions =
list(Dimension(name = areaVar, keys = "840"),
Dimension(name = yearVar, keys = as.character(2011)),
Dimension(name = elementVar, keys = "5120"),
Dimension(name = itemVar, keys = c(wheatKeys, cattleKeys,
palmOilKeys, sugarKeys))
))
###############################################################################
## Build Model
###############################################################################
if(buildModel){
finalModelData =
{
requiredItems <<- getAllItemCPC()
production <<- getProductionData()
import <<- getImportData()
loss <<- getOfficialLossData()
## NOTE (Michael): Don't really need world bank data, as those
##                 variables does not aid to the model
##
## wb <<- getLossWorldBankData()
lossFoodGroup <<- getLossFoodGroup()
lossRegionClass <<- getLossRegionClass()
countryTable <<-
GetCodeList(domain = "agriculture",
dataset = "agriculture",
dimension = areaVar)[type == "country",
list(code, description)]
setnames(countryTable,
old = c("code", "description"),
new = c(areaVar, "geographicAreaM49Name"))
} %>%
mergeAllLossData(lossData = loss,
production, import, lossFoodGroup,
lossRegionClass, countryTable) %>%
subset(x = .,
subset = Value_measuredElement_5120 > 0 &
foodGeneralGroup == "primary" &
Value_measuredElement_5510 != 0,
select = c("geographicAreaM49", "geographicAreaM49Name",
"measuredItemCPC", "timePointYears",
"Value_measuredElement_5120", "Value_measuredElement_5510",
"Value_measuredElement_5600", "foodGroupName",
"foodPerishableGroup", "lossRegionClass")) %>%
removeCarryLoss(data = ., lossVar = "Value_measuredElement_5120") %>%
## Convert variables to factor
.[, `:=`(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
lapply(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
FUN = function(x) as.factor(.SD[[x]])
)
)
]
## NOTE (Michael): Here we have not yet added in import yet, since
##                 there are only data for 2010. However, import
##                 should be added when it is available.
## lossLmeModel =
##     lmer(log(Value_measuredElement_5120) ~ -1 + timePointYears +
##          log(Value_measuredElement_5510 + 1) +
##          (log(Value_measuredElement_5510 + 1)|
##               lossRegionClass/geographicAreaM49Name:
##                   foodPerishableGroup/foodGroupName/measuredItemCPC),
##          data = finalModelData)
lossLmeModel =
lmer(log(Value_measuredElement_5120) ~ timePointYears +
log(Value_measuredElement_5510 + 1) +
(-1 + log(Value_measuredElement_5510 + 1)|
foodPerishableGroup/foodGroupName/measuredItemCPC/geographicAreaM49Name),
data = finalModelData)
lossLmeVariance = bootMer(lossLmeModel,
FUN = function(lossLmeModel) predict(lossLmeModel),
nsim = 2)
save(c(lossLmeModel,lossLmeVariance), file = lossModelPath)
} else {
load(lossModelPath)
}
###############################################################################
## Predict with model
###############################################################################
finalPredictData =
{
requiredItems <<- c(wheatKeys, cattleKeys, palmOilKeys, sugarKeys)
production <<- getProductionData()
import <<- getImportData()
lossFoodGroup <<- getLossFoodGroup()
lossRegionClass <<- getLossRegionClass()
countryTable <<-
GetCodeList(domain = "agriculture",
dataset = "agriculture",
dimension = "geographicAreaM49")[type == "country",
list(code, description)]
setnames(countryTable,
old = c("code", "description"),
new = c("geographicAreaM49", "geographicAreaM49Name"))
loss <<- getSelectedLossData()
} %>%
mergeAllLossData(lossData = loss,
production, import, lossFoodGroup,
lossRegionClass, countryTable) %>%
subset(x = .,
## Why these filters??  The first prevents missing values from ever
## being imputed.
subset = #Value_measuredElement_5120 > 0 &
foodGeneralGroup == "primary",
#Value_measuredElement_5510 != 0,
select = c("geographicAreaM49", "geographicAreaM49Name",
"measuredItemCPC", "timePointYears", "Value_measuredElement_5120",
"flagObservationStatus_measuredElement_5120",
"flagMethod_measuredElement_5120",
"Value_measuredElement_5510", "Value_measuredElement_5600",
"foodGroupName", "foodPerishableGroup", "lossRegionClass")) %>%
removeCarryLoss(data = ., lossVar = "Value_measuredElement_5120") %>%
## Convert variables to factor
.[, `:=`(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
lapply(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
FUN = function(x) as.factor(.SD[[x]])
)
)
]
## Impute selected data
finalPredictData = imputeLoss(data = finalPredictData,
lossVar = "Value_measuredElement_5120",
lossObservationFlagVar =
"flagObservationStatus_measuredElement_5120",
lossMethodFlagVar = "flagMethod_measuredElement_5120",
lossModel = lossLmeModel,
lossVarModel = lossLmeVariance)
lossEstimates = finalPredictData
lossEstimates[, timePointYears := as.character(timePointYears)]
lossEstimates
apply(lossLmeVariance$t,2,sd)
apply(lossLmeVariance$t,1,sd)
dim(lossLmeVariance)
length(lossLmeVariance)
length(lossLmeVariance$t)
dim(lossLmeVariance$t)
lossLmeVariance$t[,`1]
lossLmeVariance$t[,1]
lossLmeVariance$t[1,]
lossLmeVariance$t[1,1]
dim(lossLmeVariance$t)
lossLmeVariance$t[,1]
lossLmeVariance$t[,2]
sd(lossLmeVariance$t[,2])
lossEstimates
finalPredictData
as.data.frame(finalPredictData)
lossLmeModel
newdata
imputedData
imputedData[which(imputedData$measuredItemCPC==0111),]
imputedData[,1]
imputedData[1,]
imputedData[which(imputedData$measuredItemCPC==011),]
imputedData[which(imputedData$measuredItemCPC= 011),]
imputedData[which(imputedData$measuredItemCPC== 0111),]
imputedData[which(imputedData$measuredItemCPC== '0142'),]
imputedData[which(imputedData$measuredItemCPC== '0111'),]
imputedData
finalPredictData =
{
requiredItems <<- c(wheatKeys, cattleKeys, palmOilKeys, sugarKeys)
production <<- getProductionData()
import <<- getImportData()
lossFoodGroup <<- getLossFoodGroup()
lossRegionClass <<- getLossRegionClass()
countryTable <<-
GetCodeList(domain = "agriculture",
dataset = "agriculture",
dimension = "geographicAreaM49")[type == "country",
list(code, description)]
setnames(countryTable,
old = c("code", "description"),
new = c("geographicAreaM49", "geographicAreaM49Name"))
loss <<- getSelectedLossData()
} %>%
mergeAllLossData(lossData = loss,
production, import, lossFoodGroup,
lossRegionClass, countryTable) %>%
subset(x = .,
## Why these filters??  The first prevents missing values from ever
## being imputed.
subset = #Value_measuredElement_5120 > 0 &
foodGeneralGroup == "primary",
#Value_measuredElement_5510 != 0,
select = c("geographicAreaM49", "geographicAreaM49Name",
"measuredItemCPC", "timePointYears", "Value_measuredElement_5120",
"flagObservationStatus_measuredElement_5120",
"flagMethod_measuredElement_5120",
"Value_measuredElement_5510", "Value_measuredElement_5600",
"foodGroupName", "foodPerishableGroup", "lossRegionClass","lossVariance")) %>%
removeCarryLoss(data = ., lossVar = "Value_measuredElement_5120") %>%
## Convert variables to factor
.[, `:=`(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
lapply(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
FUN = function(x) as.factor(.SD[[x]])
)
)
]
subset
select = c("geographicAreaM49", "geographicAreaM49Name",
"measuredItemCPC", "timePointYears", "Value_measuredElement_5120",
"flagObservationStatus_measuredElement_5120",
"flagMethod_measuredElement_5120",
"Value_measuredElement_5510", "Value_measuredElement_5600",
"foodGroupName", "foodPerishableGroup", "lossRegionClass","lossVariance"))
select = c("geographicAreaM49", "geographicAreaM49Name",
"measuredItemCPC", "timePointYears", "Value_measuredElement_5120",
"flagObservationStatus_measuredElement_5120",
"flagMethod_measuredElement_5120",
"Value_measuredElement_5510", "Value_measuredElement_5600",
"foodGroupName", "foodPerishableGroup", "lossRegionClass","lossVariance")
subset(x = .,
## Why these filters??  The first prevents missing values from ever
## being imputed.
subset = #Value_measuredElement_5120 > 0 &
foodGeneralGroup == "primary",
#Value_measuredElement_5510 != 0,
select = c("geographicAreaM49", "geographicAreaM49Name",
"measuredItemCPC", "timePointYears", "Value_measuredElement_5120",
"flagObservationStatus_measuredElement_5120",
"flagMethod_measuredElement_5120",
"Value_measuredElement_5510", "Value_measuredElement_5600",
"foodGroupName", "foodPerishableGroup", "lossRegionClass","lossVariance")) %>%
removeCarryLoss(data = ., lossVar = "Value_measuredElement_5120") %>%
## Convert variables to factor
.[, `:=`(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
lapply(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
FUN = function(x) as.factor(.SD[[x]])
)
)
]
lossData
requiredItems <<- c(wheatKeys, cattleKeys, palmOilKeys, sugarKeys)
production <<- getProductionData()
import <<- getImportData()
lossFoodGroup <<- getLossFoodGroup()
lossRegionClass <<- getLossRegionClass()
lossRegionClass
countryTable <<-
GetCodeList(domain = "agriculture",
dataset = "agriculture",
dimension = "geographicAreaM49")[type == "country",
list(code, description)]
setnames(countryTable,
old = c("code", "description"),
new = c("geographicAreaM49", "geographicAreaM49Name"))
loss <<- getSelectedLossData()
mergeAllLossData(lossData = loss,
production, import, lossFoodGroup,
lossRegionClass, countryTable) %>%
subset(x = .,
## Why these filters??  The first prevents missing values from ever
## being imputed.
subset = #Value_measuredElement_5120 > 0 &
foodGeneralGroup == "primary",
#Value_measuredElement_5510 != 0,
select = c("geographicAreaM49", "geographicAreaM49Name",
"measuredItemCPC", "timePointYears", "Value_measuredElement_5120",
"flagObservationStatus_measuredElement_5120",
"flagMethod_measuredElement_5120",
"Value_measuredElement_5510", "Value_measuredElement_5600",
"foodGroupName", "foodPerishableGroup", "lossRegionClass","lossVariance")) %>%
removeCarryLoss(data = ., lossVar = "Value_measuredElement_5120") %>%
## Convert variables to factor
.[, `:=`(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
lapply(c("measuredItemCPC", "foodGroupName",
"foodPerishableGroup", "lossRegionClass"),
FUN = function(x) as.factor(.SD[[x]])
)
)
]
